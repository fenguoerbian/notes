\documentclass[a4paper,12pt]{article}
\usepackage{geometry}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\renewcommand{\textfraction}{0.15}
\renewcommand{\topfraction}{0.85}
\renewcommand{\bottomfraction}{0.65}
\renewcommand{\floatpagefraction}{0.60}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amsthm}
\usepackage{extarrows}
\usepackage{bm}
% \newcommand{\bm}{\symbfit}    % `bm` confilicts with `unicode-math`. In that case use \symbfit for bold math symbols
\usepackage{graphicx}
\usepackage[section]{placeins}
\usepackage{flafter}
\usepackage{array}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{color}
\usepackage{multirow}
\usepackage{natbib}
% \usepackage{enumerate}
\usepackage{enumitem}    % more flexible than `enumerate` package, the reference will carry the whole label appearance, not just the counter, unlike the `enumerate` package.
\usepackage{upgreek}    % 'upgreek' letters

% \pdfstringdefDisableCommands{\let\bm=\relax}

\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\newtheorem{assum}{Assumption}
\newtheorem{rem}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem{prop}{Proposition}

\setcounter{topnumber}{5}    % Maximum number of floats that can appear at the top of a text page; default 2. 
\setcounter{bottomnumber}{5}   % Maximum number of floats that can appear at the bottom of a text page; default 1. 
\setcounter{totalnumber}{10}    % Maximum number of floats that can appear on a text page; default 3. 

\DeclareMathOperator*{\argmaxdown}{arg\,max}
\DeclareMathOperator*{\argmindown}{arg\,min}
\DeclareMathOperator{\argmax}{arg\,max}
\DeclareMathOperator{\argmin}{arg\,min}

% cross-reference to other files
% the externaldocument should be compiled 
% (and at least twice if you're using xr-hyper)
% \usepackage{xr-hyper}
% \usepackage{xr}

% --- external document (ordinary setting) ---
% \externaldocument{external_tex_file}
% --- end of ordinary setting ---

% --- external document (overleaf setting) ---
% externaldocument settings for Overleaf
% \makeatletter
% \newcommand*{\addFileDependency}[1]{% argument=file name and extension
% \typeout{(#1)}
% \@addtofilelist{#1}
% \IfFileExists{#1}{}{\typeout{No file #1.}}
% }
%   \makeatother
%   \newcommand*{\myexternaldocument}[1]{%
%   \externaldocument{#1}%
%   \addFileDependency{#1.tex}%
%   \addFileDependency{#1.aux}%
% }
%   \myexternaldocument{external_tex_file}
%   --- end of overleaf setting ---

%   mathtools can be used to define labeling format for equations
%   one can use \eqref for a reference to a labeled equation.
\usepackage{mathtools}
\newtagform{supp}{(S-}{)}    % define a equation labeling format for suppliment
\usetagform{supp}            % use the supp format
\usetagform{default}         % use the default format

\usepackage{algorithmic}
\usepackage{algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

% package for hyperlinks
% It's error-prone because hyper link is quite difficult
% due to the fact the typesetting environment is complex.
% So you can disable this package and finish the document.
% Then sort out the hyperlink thing.
\usepackage[colorlinks,linkcolor=red,anchorcolor=blue,citecolor=green,CJKbookmarks=True]{hyperref}

% package for displaying highlighted codes
\usepackage{minted}

% package for input codec and output rendering font
\usepackage[utf8]{inputenc}    % it is always good practice to use utf8
% you can also try latin1, latin2, cp1252 and cp1250
\usepackage[T1]{fontenc}    % the default is T0, which only contains 128 characters
% you can try T1, T2A, T2B
% you can refer to https://www.overleaf.com/learn/latex/international_language_support#Font_encoding
% for more details.


\title{Stratified v.s. Unstratified Analysis}
\author{Chao Cheng}
\date{\today}



\begin{document}
\maketitle
\tableofcontents{}

\section{Introduction}
\label{sec:introduction}

In this note we will talk about the Cox's proportional hazards (Cox's PH) model. And more specifically, what will happen when unstratified analysis is used for a data where stratified analysis is the true model. 

\section{A simple parametric model}
\label{sec:simple-param-model}

Consider the Weibull distribution, denote $T \sim W(p, \lambda)$. Then

\[
  \begin{aligned}
    & f\left(t\right) = p\lambda^pt^{p - 1}\mathrm{exp}\left(-\left(\lambda t\right)^p\right)    \\
    & F\left(t\right) = 1 - \mathrm{exp}\left(-\left(\lambda t\right)^p\right)
      \quad\quad S\left(t\right) = \mathrm{exp}\left(-\left(\lambda t\right)^p\right)    \\
    & h\left(t\right) = p\lambda^pt^{p - 1}    \\
    & H\left(t\right) = \left(\lambda t\right)^p    \\
    & \mathrm{E}\left(T\right) = \frac{1}{\lambda} \cdot \Gamma\left(1 + \frac{1}{p}\right)
      \quad\quad \mathrm{Var}\left(T\right) = \frac{1}{\lambda^2}\left(
      \Gamma\left(1 + \frac{2}{p}\right)
      - \Gamma\left(1 + \frac{1}{p}\right)
      \right)    \\
    & \mathrm{E}\left(T^m\right) = \frac{1}{\lambda^m}\Gamma\left(1 + \frac{m}{p}\right)
  \end{aligned}
\]

Then the likelihood is

\begin{equation}
  \label{eq:weibull_likelihood}
  \begin{aligned}
    L\left(t_1, \cdots, t_n\middle|p, \lambda_1, \cdots, \lambda_n\right)
    &= \prod\limits_{i = 1}^n\left(
    f(t_i)^{\delta_i}\left(1 - F\left(t_i\right)\right)^{1 - \delta_i}
    \right)
    = \prod\limits_{i = 1}^n\left(
    h\left(t_i\right)^{\delta_i}S\left(t_i\right)
    \right)    \\
    &= \prod\limits_{i = 1}^n
      \left(p\lambda_i^{p}t_i^{p - 1}\right)^{\delta_i}
      \mathrm{exp}\left(-\left(\lambda_i t_i\right)^p\right)
  \end{aligned}
\end{equation}

where $\delta_i = 1$ means an event is observed for $i$. Otherwise $\delta_i = 0$ represents censor is observed. Note that in \eqref{eq:weibull_likelihood}, we assume all subjects share the same $p$ in the Weibull distribution, but their $\lambda$s can be different. 



\section{Cox model}
\label{sec:cox-model}

For a Cox model, the key assumption is constant hazard ratio, that is
\[
  h\left(t\middle|Z\right) = h_0\left(t\right)\cdot e^{\beta Z}
\]

And if we plug-in the Weibull distribution, that is $h_0\left(t\right) = p\lambda_0^pt^{p - 1}$. Then
\[
  h\left(t\middle|Z\right)
  = h_0\left(t\right)\cdot e^{\beta Z}
  = p\lambda_0^pt^{p - 1} \cdot e^{\beta Z}
  = p \left(\lambda_0 e^{\beta Z / p}\right)^p t^{p - 1}
\]

Here for our purpose, we let $Z_i \in \left\{0, 1\right\}$ denote the treatment(1) or control(0) group. And in this case, the data likelihood \eqref{eq:weibull_likelihood} becomes
\[
  \begin{aligned}
    L\left(t_1, \cdots, t_n\middle| p, \lambda, \beta\right)
    &= \prod\limits_{i = 1}^n
    \left(p \left(\lambda e^{\beta Z_i/p}\right)^pt_i^{p - 1}\right)^{\delta_i}
    \mathrm{exp}\left(-\left(\lambda e^{\beta Z_i/p} t_i\right)^p\right)    \\
    &= \prod\limits_{i = 1}^n
    \left(p \lambda^p e^{\beta Z_i} t_i^{p - 1}\right)^{\delta_i}
    \mathrm{exp}\left(-\left(\lambda t_i\right)^p e^{\beta Z_i}\right)
  \end{aligned}
\]

And the loglikelihood is
\begin{equation}
  \label{eq:weibull_loglikelihood}
  \begin{aligned}
    \mathrm{log}L
    &= \sum\limits_{i = 1}^n
      \delta_i\left(
      \mathrm{log}p + p\mathrm{log}\lambda + \beta Z_i + \left(p - 1\right)t_i
      \right)
      - \left(\lambda t_i\right)^p e^{\beta Z_i}    \\
    &= n_{evt}\left(\mathrm{log}p + p \mathrm{log}\lambda\right)
      + \sum\limits_{i = 1}^n\delta_i\left(\beta Z_i + \left(p - 1\right)t_i\right)
      - \lambda^p\sum\limits_{i = 1}^nt_i^pe^{\beta Z_i}
  \end{aligned}
\end{equation}

Use the profile likelihood method, first we fix $\beta$ and $p$ to maximize $\mathrm{log}L$ w.r.t $\lambda$:
\[
  \begin{aligned}
    \frac{\partial\mathrm{log}L}{\partial \lambda}
    = \frac{n_{evt}p}{\lambda}
    - p\lambda^{p - 1}\sum\limits_{i = 1}^nt_i^pe^{\beta Z_i}
  \end{aligned}
\]
Set this to 0 we have
\[
  \hat{\lambda} = \left(
    \frac{n_{evt}}{\sum\limits_{i = 1}^nt_i^pe^{\beta Z_i}}
  \right)^{1 / p}
\]
Plug this back into \eqref{eq:weibull_loglikelihood} will give us
\[
  \begin{aligned}
    \mathrm{log}L
    &= n_{evt}\left(
      \mathrm{log}p + \mathrm{log}n_{evt}
      - \mathrm{log}\left(\sum\limits_{i = 1}^nt_i^pe^{\beta Z_i}\right)
      \right)
      + \sum\limits_{i = 1}^n\delta_i\left(\beta Z_i + \left(p - 1\right)t_i\right)
      - \frac{n_{evt}}{\sum\limits_{i = 1}^nt_i^pe^{\beta Z_i}} \cdot \sum\limits_{i = 1}^nt_i^pe^{\beta Z_i}    \\
    &= n_{evt}\left(
      \mathrm{log}p + \mathrm{log}n_{evt}
      - \mathrm{log}\left(\sum\limits_{i = 1}^nt_i^pe^{\beta Z_i}\right)
      \right)
      + \sum\limits_{i = 1}^n\delta_i\left(\beta Z_i + \left(p - 1\right)t_i\right)
      - n_{evt}
  \end{aligned} 
\]
Unfortunately, there's no analytical solution to $p$ even when we fixed $\beta$. So let's consider a simpler case where we fix $p = 1$, i.e. Exponential distribution. Then this loglikelihood becomes
\[
  \begin{aligned}
    \mathrm{log}L
    &= n_{evt}\left(
      \mathrm{log}n_{evt}
      - \mathrm{log}\left(\sum\limits_{i = 1}^nt_ie^{\beta Z_i}\right)
      \right)
      + \sum\limits_{i = 1}^n\delta_i\beta Z_i
      - n_{evt}    \\
    &\overset{w.r.t\; \beta}{\propto}
      -n_{evt}\mathrm{log}\left(\sum\limits_{i = 1}^nt_ie^{\beta Z_i}\right)
      +  \sum\limits_{i = 1}^n\delta_i\beta Z_i    \\
    &= \sum\limits_{i = 1}^n\delta_i\left(
      \beta Z_i - \mathrm{log}\left(\sum\limits_{i = 1}^nt_ie^{\beta Z_i}\right)
      \right)    \\
    &= \sum\limits_{i = 1}^n\delta_i\mathrm{log}
      \frac{e^{\beta Z_i}}{\sum\limits_{i = 1}^nt_ie^{\beta Z_i}}
  \end{aligned}
\]
Therefore to maximize $\mathrm{log}L$ with respect to $\beta$, is equivalent to maximize the following term
\begin{equation}
  \label{eq:beta_mle_objective}
  \prod\limits_{i = 1}\left(
    \frac{e^{\beta Z_i}}{\sum\limits_{i = 1}^nt_ie^{\beta Z_i}}
  \right)^{\delta_i}
\end{equation}

We can take derivative of $\mathrm{log}L$ and try to solve for $\beta$ by setting the derivative to 0:
\[
  \begin{aligned}
    \frac{\partial \mathrm{log}L}{\partial \beta}
    &= \frac{\partial}{\partial\beta}
      \sum\limits_{i = 1}^n\delta_i\left(
      \beta Z_i - \mathrm{log}\left(\sum\limits_{i = 1}^nt_ie^{\beta Z_i}\right)
      \right)    \\
    &= n_{evt \,\&\, trt}
      - \frac{\partial}{\partial\beta}
      \left(n_{evt} \cdot
      \mathrm{log}\left(\sum\limits_{i = 1}^nt_ie^{\beta Z_i}\right)
      \right)    \\
    &= n_{evt\,\&\,trt}
      - n_{evt}\cdot \left(
      \frac{\sum\limits_{i = 1}^nt_iZ_ie^{\beta Z_i}}{\sum\limits_{i = 1}^nt_ie^{\beta Z_i}}
      \right)    \\
    &= n_{evt\,\&\,trt}
      - n_{evt} \cdot
      \frac{\sum\limits_{i\in\;trt}t_ie^{\beta}}{
      \sum\limits_{i\in\;trt}t_ie^{\beta} + \sum\limits_{i\in\;ctrl}t_i}
  \end{aligned}
\]
where we use the notation that $Z_i\in\left\{0, 1\right\}$ to indicate control and treatment group and $\delta_i\in\left\{0, 1\right\}$ to indicate observed censor or event. Setting $\frac{\partial\mathrm{log}L}{\partial \beta} = 0$ we have the MLE:
\begin{equation}
  \label{eq:beta_mle_exponential}
  \hat{\beta} = \mathrm{log}\left(
    \frac{n_{evt\,\&\,trt}}{n_{evt\;\&\;ctrl}}
    \cdot
    \frac{\sum\limits_{i\in\;ctrl}t_i}{\sum\limits_{i\in\;trt}t_i}
  \right)
\end{equation}
\textbf{Note:} \eqref{eq:beta_mle_objective} can be seen as objective function for $\beta$'s MLE and it is \textbf{different} from the partial likelihood used in Cox regression, which is
\[
  \prod\limits_{i = 1}^n\left(
    \frac{e^{\beta Z_i}}{\sum\limits_{\left\{j\middle|t_j\geq t_i\right\}}e^{\beta Z_j}}
  \right)^{\delta_i}
\]



\subsection{Stratified setting}
\label{sec:stratified-setting}

Now let's consider the stratified setting, with $K$ strata. Then for each stratum $k\in\left\{1, \cdots, K\right\}$, the Weibull distribution for control group is $W\left(p_k, \lambda_k\right)$, which means the hazard is
\[
  h_{0, k}\left(t\right) = p_k\lambda_k^{p_k}t^{p_k - 1}.
\]

Assume the constant hazard ratio is $e^\beta$. Then the hazard for treatment group is $h_{1, k}\left(t\right) = h_{0, k}\left(t\right)e^\beta$. Therefore
\[
  h_k\left(t\middle|Z\right) = h_{0, k}\left(t\right)e^{\beta Z},\quad Z\in\left\{0, 1\right\}. 
\]

In this case, assume sample size in each stratum are $n_1, \cdots, n_K$. Then the observed time is
\[
  \begin{aligned}
    \bm{t}
    &=
      \left(
      t_{i,k}
      ,\;
      i\in\left\{1, \cdots, n_k\right\}
      \;
      k\in\left\{1, \cdots, K\right\}
      \right)^T    \\
    &= \left(
      \bm{t}_1^T, \bm{t}_2^T, \cdots, \bm{t}_K^T
      \right)^T    \\
    &= \left(
      t_{1, 1}, \cdots, t_{n_1, 1};
      t_{1, 2}, \cdots, t_{n_2, 2};
      \cdots ;
      t_{1, K}, \cdots, t_{n_K, K}
      \right)^T
  \end{aligned} 
\]
The corresponding covariate (treatment allocation) vector is
\[
  \begin{aligned}
    \bm{Z}
    &= \left(
      \bm{Z}_1^T, \cdots, \bm{Z}_K^T
      \right)^T    \\
    &= \left(
      z_{1, 1}, \cdots, z_{n_1, 1};
      z_{1, 2}, \cdots, z_{n_2, 2};
      \cdots ;
      z_{1, K}, \cdots, z_{n_K, K}
      \right)^T
  \end{aligned}
\]
The parameter vectors are
\[
  \begin{aligned}
    & \bm{p} = \left(p_1, \cdots, p_K\right)^T    \\
    & \bm{\lambda} = \left(\lambda_1, \cdots, \lambda_K\right)^T
  \end{aligned}
\]
And the data likelihood is
\[
  \begin{aligned}
    L\left(
    \bm{t}; \bm{Z}
    \middle|
    \bm{p}, \bm{\lambda}, \beta
    \right)
    &= \prod\limits_{k = 1}^K
      L\left(\bm{t}_k; \bm{Z}_k\middle| p_k, \lambda_k, \beta\right)    \\
    &= \prod\limits_{k = 1}^K\prod\limits_{i = 1}^{n_k}
      \left(
      p_k\lambda_k^{p_k}e^{\beta Z_{i, k}}t_{i, k}^{p_k - 1}
      \right)^{\delta_{i, k}}
      \mathrm{exp}\left(
      - \left(\lambda_k t_{i, k}\right)^{p_k}
      e^{\beta Z_{i, k}}
      \right)
  \end{aligned}
\]
And the partial likelihood would be
\[
  \begin{aligned}
    L_1\left(\bm{t}; \bm{Z}\middle|\bm{p}, \bm{\lambda}, \beta\right)
    &= \prod\limits_{k = 1}^KL_1\left(\bm{t}_k; \bm{Z}_k\middle| p_k, \lambda_k, \beta\right)    \\
    &= \prod\limits_{k = 1}^K\prod\limits_{i = 1}^{n_k}
      \left(
      \frac{
      e^{\beta Z_{i, k}}}{
      \sum\limits_{\left\{j\middle|t_{j, k}\geq t_{i, k}\right\}}e^{\beta Z_{j, k}}}
      \right)^{\delta_{i, k}}
  \end{aligned}
\]

\subsection{Unstratified analysis under stratified setting}
\label{sec:unstr-analys-under}

We use $f_k\left(t\right)$, $F_k\left(t\right)$, $S_k\left(t\right)$ and $h_k\left(t\right)$ to denote the p.d.f, c.d.f, survival function and hazard function of stratum $k$. Then we have marginally, the c.d.f of event time
\[
  \begin{aligned}
    F\left(t\right) = P\left(T \leq t\right)
    = \sum\limits_{k = 1}^K P\left(T \leq t,\quad \text{T from stratum k}\right)
    = \sum\limits_{k = 1}^K \pi_k F_k\left(t\right)
  \end{aligned}
\]
where $\pi_k = P\left(\text{T from stratum k}\right)$ denotes the probability that the subject comes from stratum $k$. Therefore
\[
  \begin{aligned}
    f\left(t\right)
    &= \frac{\partial F}{\partial t} = \sum\limits_{k = 1}^K\pi_kf_k\left(t\right)    \\
    S\left(t\right)
    &= 1 - F\left(t\right) = 1 - \sum\limits_{k = 1}^K\pi_kF_k\left(t\right)
      = \sum\limits_{k = 1}^K\pi_k S_k\left(t\right)    \\
    h\left(t\right)
    &= \frac{f\left(t\right)}{S\left(t\right)}
      = \frac{\sum\limits_{k = 1}^K\pi_kf_k\left(t\right)}{\sum\limits_{k = 1}^K\pi_k S_k\left(t\right)}
  \end{aligned}
\]

So for a subject from control group, the hazard function (still based on Weibull distribution) is
\begin{equation}
  \label{eq:control_marginal_hazard}
  h_0\left(t\right) =
  \frac{
    \sum\limits_{k = 1}^K\pi_k
    p_k\lambda_k^{p_k}t^{p_k - 1}
    \mathrm{exp}\left(-\left(\lambda_kt\right)^{p_k}\right)
  }{
    \sum\limits_{k = 1}^K\pi_k
    \mathrm{exp}\left(-\left(\lambda_kt\right)^{p_k}\right)
  }
\end{equation}
And the hazard function for treatment group is
\begin{equation}
  \label{eq:treatment_marginal_hazard}
  h_1\left(t\right) =
  \frac{
    \sum\limits_{k = 1}^K\pi_k
    p_k\lambda_k^{p_k}t^{p_k - 1}e^\beta
    \mathrm{exp}\left(-\left(\lambda_kt\right)^{p_k}e^\beta\right)
  }{
    \sum\limits_{k = 1}^K\pi_k
    \mathrm{exp}\left(-\left(\lambda_kt\right)^{p_k}e^\beta\right)
  }
\end{equation}

Therefore the \textbf{Hazard Ratio} is
\begin{equation}
  \label{eq:marginal_hr}
  hr\left(t\right) = \frac{h_1\left(t\right)}{h_0\left(t\right)}
  = \frac{
    \frac{
      \sum\limits_{k = 1}^K\pi_k
      p_k\lambda_k^{p_k}t^{p_k - 1}e^\beta
      \mathrm{exp}\left(-\left(\lambda_kt\right)^{p_k}e^\beta\right)
    }{
      \sum\limits_{k = 1}^K\pi_k
      \mathrm{exp}\left(-\left(\lambda_kt\right)^{p_k}e^\beta\right)
    }
  }{
    \frac{
      \sum\limits_{k = 1}^K\pi_k
      p_k\lambda_k^{p_k}t^{p_k - 1}
      \mathrm{exp}\left(-\left(\lambda_kt\right)^{p_k}\right)
    }{
      \sum\limits_{k = 1}^K\pi_k
      \mathrm{exp}\left(-\left(\lambda_kt\right)^{p_k}\right)
    }
  }, 
\end{equation}
which is \textbf{NOT CONSTANT} w.r.t. $t$, meaning the constant hazard ratio assumption for Cox regression is violated.
\par
Even for a simple case, where we assume $p_k = 1, k = 1, \cdots, K$, we still have
\begin{equation}
  \label{eq:marginal_hr_exponential}
  hr(t) = \frac{
    \frac{
      \sum\limits_{k = 1}^K\pi_k
      \lambda_ke^\beta
      \mathrm{exp}\left(-\lambda_kte^\beta\right)
    }{
      \sum\limits_{k = 1}^K\pi_k
      \mathrm{exp}\left(-\lambda_kte^\beta\right)
    }
  }{
    \frac{
      \sum\limits_{k = 1}^K\pi_k
      \lambda_k
      \mathrm{exp}\left(- \lambda_kt\right)
    }{
      \sum\limits_{k = 1}^K\pi_k
      \mathrm{exp}\left(-\lambda_kt\right)
    }
  }
  = \frac{
    \left(
      \sum\limits_{k = 1}^K\pi_k
      \mathrm{exp}\left(-\lambda_kt\right)
    \right)
    \left(
      \sum\limits_{k = 1}^K\pi_k
      \lambda_ke^\beta
      \mathrm{exp}\left(-\lambda_kte^\beta\right)
    \right)
  }{
    \left(
      \sum\limits_{k = 1}^K\pi_k
      \lambda_k
      \mathrm{exp}\left(- \lambda_kt\right)
    \right)
    \left(
      \sum\limits_{k = 1}^K\pi_k
      \mathrm{exp}\left(-\lambda_kte^\beta\right)
    \right)
  }, 
\end{equation}
which again, is \textbf{NOT CONSTANT} w.r.t. $t$.
\par
And this implies that using unstratified analysis under a stratified setting might lead to {\color{red} biased} estimation of hazard ratio. 

\bibliographystyle{plainnat}
\bibliography{../../ref}





\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
